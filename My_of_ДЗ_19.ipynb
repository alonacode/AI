{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alonacode/AI/blob/main/My_of_%D0%94%D0%97_19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Завдання 1\n",
        "Напишіть функцію, яка повертає список фраз з тексту, які відповідають певному шоблону. При необхідності можете добавити власні параметри.\n",
        "\n",
        "Протестуйте функцію на якомусь тексті."
      ],
      "metadata": {
        "id": "D56Rwjf4EXC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_phrases(text, regex, tag_name):\n",
        "  \"\"\"\n",
        "  Reurn list of phrases from text that matches regex\n",
        "\n",
        "  Params:\n",
        "    text: str - original text\n",
        "    regex: str - regular expression\n",
        "    tag_name: str - tag name that is used in nltk tree\n",
        "\n",
        "  Return:\n",
        "    phrases: list[str] - list of phrases\n",
        "  \"\"\""
      ],
      "metadata": {
        "id": "G4Stff_zFQjv"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tag import pos_tag\n",
        "from nltk.chunk import RegexpParser\n",
        "\n",
        "# Завантажуємо необхідні ресурси NLTK (для токенізації, тегування та stop-слова)\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def get_phrases(text, tag_name):\n",
        "\n",
        "    # Токенізація тексту\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Отримуємо список stop-слова на англійській мові\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    # Фільтрація токенів (видаляємо stop-слова)\n",
        "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "\n",
        "    # Виконання POS тегування для відфільтрованих слів\n",
        "    tagged = pos_tag(filtered_tokens)\n",
        "\n",
        "    # Оновлена граматика для розбору\n",
        "    grammar = f\"{tag_name}: {{<NN.*><VB.*> | <VB.*><NN.*>}}\"\n",
        "\n",
        "    # Створюємо парсер\n",
        "    chunk_parser = RegexpParser(grammar)\n",
        "\n",
        "    # Парсинг тексту з тегами\n",
        "    tree = chunk_parser.parse(tagged)\n",
        "\n",
        "    # Збираємо фрази, які відповідають заданому тегу\n",
        "    phrases = []\n",
        "\n",
        "    # Перевіряємо кожен піддерево в дереві\n",
        "    for subtree in tree:\n",
        "        if isinstance(subtree, nltk.Tree) and subtree.label() == tag_name:\n",
        "            phrase = ' '.join(word for word, tag in subtree)\n",
        "            phrases.append(phrase)\n",
        "\n",
        "    return phrases\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmwNDUWagzQk",
        "outputId": "6b88190b-b77a-484c-9dd1-b627ecc122ba"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "John enjoys playing football in the park every weekend. He often meets his friends there.\n",
        "They usually play in teams, and sometimes they have small competitions.\n",
        "Mary loves running, and she runs every morning to stay fit. John and Mary are good friends,\n",
        "and they often hang out together after their exercise.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "tag_name = 'NV'\n",
        "result = get_phrases(text, tag_name)\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhSn_Kejg6V_",
        "outputId": "4da21eaa-8294-45b8-8d2b-2336cd1779c4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['John enjoys', 'playing football', 'meets friends', 'play teams', 'Mary loves']\n"
          ]
        }
      ]
    }
  ]
}