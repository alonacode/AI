{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alonacode/AI/blob/main/Copy_My_of_DZ18_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rXwBC__jrad"
      },
      "source": [
        "# Оберіть одне завдання на вибір"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVce3DOPMw84"
      },
      "source": [
        "# Завдання 1\n",
        "\n",
        "За допомогою сегментації зображень замінітть фон для зображення https://github.com/HalyshAnton/IT-Step-Pyton-AI/blob/main/module5/images/humans.jpg\n",
        "\n",
        "на фон з https://github.com/HalyshAnton/IT-Step-Pyton-AI/blob/main/module5/images/forest.jpg\n",
        "\n",
        "* отримайте маску для зображення людей, де `True` - піксель класу людини, `False` - піксель іншого класу\n",
        "* зробіть зображення лісу такого ж розміру як і зображення людей\n",
        "* застосуйте маску щоб змінити значення пікселів зображення лісу на пікселі зображення людей\n",
        "* Якщо результат поганий можете спробувати використати маску для класу `__background`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q96lWg489GUh"
      },
      "source": [
        "Варіант 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bgodx0aygf75"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50, DeepLabV3_ResNet50_Weights\n",
        "from torchvision import transforms\n",
        "from torchvision.io.image import read_image\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision.transforms import functional as F\n",
        "\n",
        "\n",
        "img = read_image('/content/humans.jpg')\n",
        "img_forest = read_image('/content/forest.jpg')\n",
        "weights = DeepLabV3_ResNet50_Weights.DEFAULT\n",
        "model = deeplabv3_resnet50(weights=weights)\n",
        "model.eval()\n",
        "transformer = weights.transforms(resize_size=520)\n",
        "batch2 = transformer(img)\n",
        "batch = batch2.unsqueeze(0)\n",
        "\n",
        "batch2.size()\n",
        "\n",
        "with torch.no_grad():\n",
        "  pred = model(batch)['out']\n",
        "\n",
        "# pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIfZMQxU11EO"
      },
      "outputs": [],
      "source": [
        "batch2.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKvkgkI7Tt1F"
      },
      "outputs": [],
      "source": [
        "batch.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjpMSrFxS9Mw"
      },
      "outputs": [],
      "source": [
        "img.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfYbopJXUr1e"
      },
      "outputs": [],
      "source": [
        "pred.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkZkLl_EU44X"
      },
      "outputs": [],
      "source": [
        "mask = pred.argmax(dim=1)\n",
        "\n",
        "mask = mask[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dwj-5oemVTz6"
      },
      "outputs": [],
      "source": [
        "mask.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0S1Uy0HVfkm"
      },
      "outputs": [],
      "source": [
        "mask.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SYtdCpeX5U6"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(img.permute(1, 2, 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDiScSXWYIIR"
      },
      "outputs": [],
      "source": [
        "plt.imshow(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qg8VaxBafOxD"
      },
      "outputs": [],
      "source": [
        "class_to_idx = {cls: idx for (idx, cls) in enumerate(weights.meta[\"categories\"])}\n",
        "class_to_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8C7yPNVeW8o"
      },
      "outputs": [],
      "source": [
        "mask_human = mask == class_to_idx['person']\n",
        "mask_human"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ckdy08O3mWut"
      },
      "outputs": [],
      "source": [
        "img_forest_resized = F.resize(img_forest, size=(520, 924))\n",
        "\n",
        "img_forest_resized.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REPYjFq5t25I"
      },
      "outputs": [],
      "source": [
        "mask_expanded = mask_human.unsqueeze(0).repeat(3, 1, 1)\n",
        "mask_expanded.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpSMm_jkuMaZ"
      },
      "outputs": [],
      "source": [
        "img_forest_np = np.array(img_forest_resized)\n",
        "img_human_np = np.array(batch2)[:, :mask_human.shape[0], :mask_human.shape[1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yORyOJiuRop"
      },
      "outputs": [],
      "source": [
        "final_img = img_forest_np.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrsIemeQugwN"
      },
      "outputs": [],
      "source": [
        "final_img[mask_expanded.numpy()] = img_human_np[mask_expanded.numpy()]\n",
        "\n",
        "# 7. Виведення результату\n",
        "final_img_rgb = final_img.transpose(1, 2, 0)\n",
        "\n",
        "\n",
        "plt.imshow(final_img_rgb)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8BFTDEl8-1k"
      },
      "source": [
        "Варіант 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRvXXbDi8E8X"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import requests\n",
        "import numpy as np\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.models.segmentation import deeplabv3_resnet101\n",
        "\n",
        "# Завантаження зображень\n",
        "img_humans = Image.open(requests.get(\"https://github.com/HalyshAnton/IT-Step-Pyton-AI/raw/main/module5/images/humans.jpg\", stream=True).raw)\n",
        "img_forest = Image.open(requests.get(\"https://github.com/HalyshAnton/IT-Step-Pyton-AI/raw/main/module5/images/forest.jpg\", stream=True).raw)\n",
        "\n",
        "# Перетворення до тензорів\n",
        "transform = T.Compose([\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "img_humans_tensor = transform(img_humans).unsqueeze(0)\n",
        "\n",
        "# Сегментаційна модель\n",
        "model = deeplabv3_resnet101(pretrained=True).eval()\n",
        "\n",
        "# Сегментація зображення\n",
        "with torch.no_grad():\n",
        "    output = model(img_humans_tensor)['out'][0]\n",
        "output_predictions = output.argmax(0).byte().cpu().numpy()\n",
        "\n",
        "# Отримання маски для людей\n",
        "# Клас людини у COCO – 15\n",
        "mask_people = (output_predictions == 15)\n",
        "\n",
        "# Зміна розміру лісу до розмірів зображення людей\n",
        "img_forest_resized = img_forest.resize(img_humans.size)\n",
        "img_forest_tensor = T.ToTensor()(img_forest_resized)\n",
        "\n",
        "# Застосування маски до зображення лісу, щоб вставити людей\n",
        "result_img = img_forest_tensor.clone()\n",
        "result_img[:, mask_people] = T.ToTensor()(img_humans)[:, mask_people]\n",
        "\n",
        "# Виведення результату\n",
        "result_img = result_img.permute(1, 2, 0).numpy()  # Переміщуємо осі для коректного відображення\n",
        "plt.imshow(result_img)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztlNAbk7PyKX"
      },
      "source": [
        "# Завдання 2\n",
        "\n",
        "Проведіть детекцію об'єктів для відео\n",
        "\n",
        "https://github.com/HalyshAnton/IT-Step-Pyton-AI/blob/main/module5/images/Highway%20driving%20during%20the%20day%20front%20view%20camera%20driving%20plate%204k%20footage.mp4\n",
        "\n",
        "Підберіть параметри для якісного виявлення машин та знаків\n",
        "Код для перетворення набору зображень у відео є нижче\n",
        "\n",
        "[документація](https://matplotlib.org/stable/api/_as_gen/matplotlib.animation.ArtistAnimation.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVBfwoHIN__M"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfsqqCoxLM53"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import torch\n",
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from pathlib import Path\n",
        "\n",
        "# Завантаження моделі YOLOv5\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5l')  # Використовуємо модель yolov5l для кращої точності\n",
        "\n",
        "# Налаштування параметрів моделі\n",
        "model.conf = 0.25  # Поріг впевненості\n",
        "model.iou = 0.5  # Поріг Intersection Over Union\n",
        "\n",
        "# Завантаження відео для обробки\n",
        "video_path = \"/content/Highway driving during the day front view camera driving plate 4k footage (1).mp4\"  # Шлях до вашого відео\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Параметри для збереження кадрів\n",
        "output_folder = \"frames\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "# Змінна для зберігання кадрів\n",
        "output_frames = []\n",
        "\n",
        "# Обробка кожного кадру відео\n",
        "frame_count = 0\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()  # Отримуємо кадр\n",
        "    if not ret:\n",
        "        break  # Якщо кадр не вдалося зчитати, виходимо з циклу\n",
        "\n",
        "    # Виконання детекції об'єктів у кадрі\n",
        "    results = model(frame)\n",
        "\n",
        "    # Малювання рамок детекції на кадрі\n",
        "    results.render()\n",
        "    output_frame = results.ims[0]  # Використовуємо ims замість imgs\n",
        "\n",
        "    # Показуємо кадр після обробки\n",
        "    # cv2.imshow('Processed Frame', output_frame)\n",
        "\n",
        "    cv2_imshow(output_frame)\n",
        "\n",
        "    # Збереження обробленого кадру як зображення\n",
        "    frame_path = os.path.join(output_folder, f\"frame_{frame_count:04d}.jpg\")\n",
        "    cv2.imwrite(frame_path, output_frame)\n",
        "    output_frames.append(output_frame)  # Зберігаємо кадр у список\n",
        "\n",
        "    # Завершення програми при натисканні клавіші 'q'\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "print(f\"Всього збережено кадрів: {frame_count}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1Rzg8y2jNmY"
      },
      "source": [
        "# Завдання 3\n",
        "\n",
        "Згенеруйте зображення на основі тексту\n",
        "\n",
        "[документація](https://huggingface.co/docs/diffusers/using-diffusers/conditional_image_generation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cFZzhQNZjl9l"
      },
      "outputs": [],
      "source": [
        "from diffusers import AutoPipelineForText2Image\n",
        "import torch\n",
        "\n",
        "# pipeline = AutoPipelineForText2Image.from_pretrained(\n",
        "# \t\"stable-diffusion-v1-5/stable-diffusion-v1-5\", torch_dtype=torch.float16, variant=\"fp16\"\n",
        "# ).to(\"cpu\")\n",
        "pipeline = AutoPipelineForText2Image.from_pretrained(\n",
        "    \"stable-diffusion-v1-5/stable-diffusion-v1-5\"\n",
        ").to(\"cpu\")\n",
        "generator = torch.Generator(\"cpu\").manual_seed(31)\n",
        "image = pipeline(\"Futuristic cityscape at dusk, glowing neon lights, flying cars, and tall skyscrapers with glass facades, soft purple and pink hues, hyper-detailed, 8k\", generator=generator).images[0]\n",
        "image"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}