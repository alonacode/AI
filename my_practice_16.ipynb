{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1449674,"sourceType":"datasetVersion","datasetId":849724}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torchvision import datasets, transforms\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import ConcatDataset, DataLoader\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"execution":{"iopub.status.busy":"2024-11-04T20:22:51.959884Z","iopub.execute_input":"2024-11-04T20:22:51.960294Z","iopub.status.idle":"2024-11-04T20:22:53.175282Z","shell.execute_reply.started":"2024-11-04T20:22:51.960249Z","shell.execute_reply":"2024-11-04T20:22:53.174394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\ndata_dir1 = '/kaggle/input/leukemia-classification/C-NMC_Leukemia/training_data/fold_0'\ndata_dir2 = '/kaggle/input/leukemia-classification/C-NMC_Leukemia/training_data/fold_1'\ndata_dir3 = '/kaggle/input/leukemia-classification/C-NMC_Leukemia/training_data/fold_2'\n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-04T20:22:53.177267Z","iopub.execute_input":"2024-11-04T20:22:53.178122Z","iopub.status.idle":"2024-11-04T20:22:53.182443Z","shell.execute_reply.started":"2024-11-04T20:22:53.178071Z","shell.execute_reply":"2024-11-04T20:22:53.181447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224, 224)),  # Пример размера\n    transforms.ToTensor(),\n])","metadata":{"execution":{"iopub.status.busy":"2024-11-04T20:22:53.183578Z","iopub.execute_input":"2024-11-04T20:22:53.183891Z","iopub.status.idle":"2024-11-04T20:22:53.194522Z","shell.execute_reply.started":"2024-11-04T20:22:53.183859Z","shell.execute_reply":"2024-11-04T20:22:53.193632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset1 = datasets.ImageFolder(root=data_dir1)\ndataset2 = datasets.ImageFolder(root=data_dir2)\ndataset3 = datasets.ImageFolder(root=data_dir3)","metadata":{"execution":{"iopub.status.busy":"2024-11-04T20:22:53.196792Z","iopub.execute_input":"2024-11-04T20:22:53.197228Z","iopub.status.idle":"2024-11-04T20:23:13.767487Z","shell.execute_reply.started":"2024-11-04T20:22:53.197197Z","shell.execute_reply":"2024-11-04T20:23:13.766427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset1.classes","metadata":{"execution":{"iopub.status.busy":"2024-11-04T20:23:13.768835Z","iopub.execute_input":"2024-11-04T20:23:13.769233Z","iopub.status.idle":"2024-11-04T20:23:13.776846Z","shell.execute_reply.started":"2024-11-04T20:23:13.769190Z","shell.execute_reply":"2024-11-04T20:23:13.775844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combined_dataset = ConcatDataset([dataset1, dataset2, dataset3])","metadata":{"execution":{"iopub.status.busy":"2024-11-04T20:23:13.778123Z","iopub.execute_input":"2024-11-04T20:23:13.778961Z","iopub.status.idle":"2024-11-04T20:23:13.789139Z","shell.execute_reply.started":"2024-11-04T20:23:13.778916Z","shell.execute_reply":"2024-11-04T20:23:13.788218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_tensor, label = combined_dataset[0]\nimage_tensor","metadata":{"execution":{"iopub.status.busy":"2024-11-04T20:23:13.790339Z","iopub.execute_input":"2024-11-04T20:23:13.790791Z","iopub.status.idle":"2024-11-04T20:23:13.854825Z","shell.execute_reply.started":"2024-11-04T20:23:13.790748Z","shell.execute_reply":"2024-11-04T20:23:13.853895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import random_split\n\ntrain_ratio = 0.8\n\n# Розділіть набір даних\ntrain_data, val_data = random_split(combined_dataset, [train_ratio, 1-train_ratio])","metadata":{"execution":{"iopub.status.busy":"2024-11-04T20:23:13.855976Z","iopub.execute_input":"2024-11-04T20:23:13.856323Z","iopub.status.idle":"2024-11-04T20:23:13.884382Z","shell.execute_reply.started":"2024-11-04T20:23:13.856291Z","shell.execute_reply":"2024-11-04T20:23:13.883442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.Resize((256, 256)), # Зміна розміру зображення до 256x256 пікселів\n    transforms.RandomHorizontalFlip(p=0.5), # Випадково перевернути по горизонталі з ймовірністю 50%\n    transforms.CenterCrop((224, 224)),\n    transforms.ToTensor(), # Перетворити зображення у тензори PyTorch\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n    \n])\n\ntest_transform = transforms.Compose([\n    transforms.Resize((256, 256)), # Зміна розміру зображення до 256x256 пікселів\n    transforms.ToTensor(), # Перетворити зображення у тензори PyTorch\n    transforms.CenterCrop((224, 224)),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])\n\n\nclass TransformDataset(torch.utils.data.Dataset):\n    def __init__(self, subset, transform=None):\n        self.subset = subset\n        self.transform = transform\n        \n    def __getitem__(self, index):\n        x, y = self.subset[index]\n        if self.transform:\n            x = self.transform(x)\n        return x, y\n        \n    def __len__(self):\n        return len(self.subset)\n\n    \ntrain_data = TransformDataset(train_data, transform = train_transform)\nval_data = TransformDataset(val_data, transform = test_transform)","metadata":{"execution":{"iopub.status.busy":"2024-11-04T20:23:13.885662Z","iopub.execute_input":"2024-11-04T20:23:13.886054Z","iopub.status.idle":"2024-11-04T20:23:13.899026Z","shell.execute_reply.started":"2024-11-04T20:23:13.885993Z","shell.execute_reply":"2024-11-04T20:23:13.897930Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_data), len(val_data)","metadata":{"execution":{"iopub.status.busy":"2024-11-04T20:23:13.903588Z","iopub.execute_input":"2024-11-04T20:23:13.904019Z","iopub.status.idle":"2024-11-04T20:23:13.913900Z","shell.execute_reply.started":"2024-11-04T20:23:13.903959Z","shell.execute_reply":"2024-11-04T20:23:13.912619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 256\n\n# Створіть завантажувачі даних\ntrain_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=batch_size)\nval_loader = torch.utils.data.DataLoader(val_data, shuffle=True, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-11-04T20:23:13.915178Z","iopub.execute_input":"2024-11-04T20:23:13.915530Z","iopub.status.idle":"2024-11-04T20:23:13.922083Z","shell.execute_reply.started":"2024-11-04T20:23:13.915497Z","shell.execute_reply":"2024-11-04T20:23:13.921214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision import models\n\nresnet18 = models.resnet18(pretrained=True)\nresnet18","metadata":{"execution":{"iopub.status.busy":"2024-11-04T20:23:13.923123Z","iopub.execute_input":"2024-11-04T20:23:13.923549Z","iopub.status.idle":"2024-11-04T20:23:14.543861Z","shell.execute_reply.started":"2024-11-04T20:23:13.923509Z","shell.execute_reply":"2024-11-04T20:23:14.543060Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"in_features = resnet18.fc.in_features\nin_features","metadata":{"execution":{"iopub.status.busy":"2024-11-04T21:38:18.875894Z","iopub.execute_input":"2024-11-04T21:38:18.876337Z","iopub.status.idle":"2024-11-04T21:38:18.883525Z","shell.execute_reply.started":"2024-11-04T21:38:18.876300Z","shell.execute_reply":"2024-11-04T21:38:18.882658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch import nn\nimport torch.nn.functional as F\nimport numpy as np\n\n\nclass TransferLearningClassifier(nn.Module):\n    def __init__(self, num_classes=10):\n        super().__init__()\n\n        resnet18 = models.resnet18(pretrained=True)\n        \n        # від'єднання градієнтів\n        for param in resnet18.parameters():\n            param.requires_grad = False\n        \n        # кількість нейронів на виході\n        in_features = resnet18.fc.in_features\n        \n        # деактивація останнього шару\n        resnet18.fc = nn.Identity()\n        \n        # створення потрібних шарів\n        self.feature_extractor = resnet18\n        \n        self.dropout = nn.Dropout(0.4)\n        self.linear = nn.Linear(in_features, num_classes)\n        \n    def forward(self, x):\n        out = self.feature_extractor(x) # (batch, in_features)\n\n        out = self.dropout(out)\n        out = self.linear(out)\n\n        return out\n\n\n    def predict(self, X, device='cpu'):\n        X = torch.FloatTensor(np.array(X)).to(device)\n\n        with torch.no_grad():\n            y_pred = F.softmax(self.forward(X), dim=-1)\n\n        return y_pred.cpu().numpy()\n\n\nmodel = TransferLearningClassifier(len(dataset1.classes)).to(device)\nmodel\n        \n        ","metadata":{"execution":{"iopub.status.busy":"2024-11-04T20:54:53.135720Z","iopub.execute_input":"2024-11-04T20:54:53.136507Z","iopub.status.idle":"2024-11-04T20:54:53.365230Z","shell.execute_reply.started":"2024-11-04T20:54:53.136459Z","shell.execute_reply":"2024-11-04T20:54:53.364201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q torchsummary","metadata":{"execution":{"iopub.status.busy":"2024-11-04T20:23:15.024567Z","iopub.execute_input":"2024-11-04T20:23:15.024879Z","iopub.status.idle":"2024-11-04T20:23:27.508964Z","shell.execute_reply.started":"2024-11-04T20:23:15.024847Z","shell.execute_reply":"2024-11-04T20:23:27.507688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchsummary import summary\n\nsummary(model, input_size=(3, 224, 224))","metadata":{"execution":{"iopub.status.busy":"2024-11-04T20:23:27.510759Z","iopub.execute_input":"2024-11-04T20:23:27.511205Z","iopub.status.idle":"2024-11-04T20:23:28.206712Z","shell.execute_reply.started":"2024-11-04T20:23:27.511156Z","shell.execute_reply":"2024-11-04T20:23:28.205754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# @title Функція для тренування\nimport time\n\ndef train(model, optimizer, loss_fn, train_dl, val_dl,\n          metrics=None, metrics_name=None, epochs=20, device='cpu', task='regression'):\n    '''\n    Runs training loop for classification problems. Returns Keras-style\n    per-epoch history of loss and accuracy over training and validation data.\n\n    Parameters\n    ----------\n    model : nn.Module\n        Neural network model\n    optimizer : torch.optim.Optimizer\n        Search space optimizer (e.g. Adam)\n    loss_fn :\n        Loss function (e.g. nn.CrossEntropyLoss())\n    train_dl :\n        Iterable dataloader for training data.\n    val_dl :\n        Iterable dataloader for validation data.\n    metrics: list\n        List of sklearn metrics functions to be calculated\n    metrics_name: list\n        List of matrics names\n    epochs : int\n        Number of epochs to run\n    device : string\n        Specifies 'cuda' or 'cpu'\n    task : string\n        type of problem. It can be regression, binary or multiclass\n\n    Returns\n    -------\n    Dictionary\n        Similar to Keras' fit(), the output dictionary contains per-epoch\n        history of training loss, training accuracy, validation loss, and\n        validation accuracy.\n    '''\n\n    print('train() called: model=%s, opt=%s(lr=%f), epochs=%d, device=%s\\n' % \\\n          (type(model).__name__, type(optimizer).__name__,\n           optimizer.param_groups[0]['lr'], epochs, device))\n\n    metrics = metrics if metrics else []\n    metrics_name = metrics_name if metrics_name else [metric.__name__ for metric in metrics]\n\n    history = {} # Collects per-epoch loss and metrics like Keras' fit().\n    history['loss'] = []\n    history['val_loss'] = []\n    for name in metrics_name:\n        history[name] = []\n        history[f'val_{name}'] = []\n\n    start_time_train = time.time()\n    \n    for epoch in range(epochs):\n\n        # --- TRAIN AND EVALUATE ON TRAINING SET -----------------------------\n        start_time_epoch = time.time()\n\n        model.train()\n        history_train = {name: 0 for name in ['loss']+metrics_name}\n\n        for batch in train_dl:\n            x    = batch[0].to(device)\n            y    = batch[1].to(device)\n            y_pred = model(x)\n            loss = loss_fn(y_pred, y)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            y_pred = y_pred.detach().cpu().numpy()\n            y = y.detach().cpu().numpy()\n\n\n            history_train['loss'] += loss.item() * x.size(0)\n            for name, func in zip(metrics_name, metrics):\n                try:\n                    history_train[name] += func(y, y_pred) * x.size(0)\n                except:\n                    if task == 'binary': y_pred_ = y_pred.round()\n                    elif task == 'multiclass': y_pred_ = y_pred.argmax(axis=-1)\n                    history_train[name] += func(y, y_pred_) * x.size(0)\n\n        for name in history_train:\n            history_train[name] /= len(train_dl.dataset)\n\n\n        # --- EVALUATE ON VALIDATION SET -------------------------------------\n        model.eval()\n        history_val = {'val_' + name: 0 for name in metrics_name+['loss']}\n\n        with torch.no_grad():\n            for batch in val_dl:\n                x    = batch[0].to(device)\n                y    = batch[1].to(device)\n                y_pred = model(x)\n                loss = loss_fn(y_pred, y)\n\n                y_pred = y_pred.cpu().numpy()\n                y = y.cpu().numpy()\n\n                history_val['val_loss'] += loss.item() * x.size(0)\n                for name, func in zip(metrics_name, metrics):\n                    try:\n                        history_val['val_'+name] += func(y, y_pred) * x.size(0)\n                    except:\n                        if task == 'binary': y_pred_ = y_pred.round()\n                        elif task == 'multiclass': y_pred_ = y_pred.argmax(axis=-1)\n\n                        history_val['val_'+name] += func(y, y_pred_) * x.size(0)\n\n        for name in history_val:\n            history_val[name] /= len(val_dl.dataset)\n\n        # PRINTING RESULTS\n\n        end_time_epoch = time.time()\n\n        for name in history_train:\n            history[name].append(history_train[name])\n            history['val_'+name].append(history_val['val_'+name])\n\n        total_time_epoch = end_time_epoch - start_time_epoch\n\n        print(f'Epoch {epoch+1:4d} {total_time_epoch:4.0f}sec', end='\\t')\n        for name in history_train:\n            print(f'{name}: {history[name][-1]:10.3g}', end='\\t')\n            print(f\"val_{name}: {history['val_'+name][-1]:10.3g}\", end='\\t')\n        print()\n        \n        # END OF TRAINING LOOP\n\n    end_time_train       = time.time()\n    total_time_train     = end_time_train - start_time_train\n    print()\n    print('Time total:     %5.2f sec' % (total_time_train))\n\n    return history","metadata":{"execution":{"iopub.status.busy":"2024-11-04T20:23:28.208436Z","iopub.execute_input":"2024-11-04T20:23:28.208852Z","iopub.status.idle":"2024-11-04T20:23:28.230829Z","shell.execute_reply.started":"2024-11-04T20:23:28.208807Z","shell.execute_reply":"2024-11-04T20:23:28.229774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Визначення функції втрат та оптимізатора\n\nloss_fn = nn.CrossEntropyLoss()\n\n# Оптимізатор (Adam) для оновлення ваг моделі\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)","metadata":{"execution":{"iopub.status.busy":"2024-11-04T20:23:28.232148Z","iopub.execute_input":"2024-11-04T20:23:28.232525Z","iopub.status.idle":"2024-11-04T20:23:28.283676Z","shell.execute_reply.started":"2024-11-04T20:23:28.232481Z","shell.execute_reply":"2024-11-04T20:23:28.282725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\nhistory = train(model, optimizer, loss_fn, train_loader, val_loader,\n                epochs=50,\n                metrics=[accuracy_score],\n                device=device,\n                task='multiclass')","metadata":{"execution":{"iopub.status.busy":"2024-11-04T20:55:34.248863Z","iopub.execute_input":"2024-11-04T20:55:34.249326Z","iopub.status.idle":"2024-11-04T21:38:18.836717Z","shell.execute_reply.started":"2024-11-04T20:55:34.249282Z","shell.execute_reply":"2024-11-04T21:38:18.835574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plot_metric(history, name):\n    plt.title(f\"Model results with {name}\")\n    plt.plot(history[name], label='train')\n    plt.plot(history['val_'+name], label='val')\n    plt.xlabel('Epoch')\n    plt.ylabel(name)\n    plt.legend()\n\n\nplot_metric(history, 'loss')","metadata":{"execution":{"iopub.status.busy":"2024-11-04T21:39:54.403958Z","iopub.execute_input":"2024-11-04T21:39:54.404658Z","iopub.status.idle":"2024-11-04T21:39:54.670153Z","shell.execute_reply.started":"2024-11-04T21:39:54.404618Z","shell.execute_reply":"2024-11-04T21:39:54.669286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_metric(history, 'accuracy_score')","metadata":{"execution":{"iopub.status.busy":"2024-11-04T21:39:59.679153Z","iopub.execute_input":"2024-11-04T21:39:59.680054Z","iopub.status.idle":"2024-11-04T21:39:59.988277Z","shell.execute_reply.started":"2024-11-04T21:39:59.679989Z","shell.execute_reply":"2024-11-04T21:39:59.987152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import ConfusionMatrixDisplay\n\nmodel = model.to('cpu')  # відключаємо від gpu\n\nloader = torch.utils.data.DataLoader(val_data, batch_size=len(val_data))\nX_test, y_test = next(iter(loader))\n\ny_pred = model.predict(X_test)\n\nConfusionMatrixDisplay.from_predictions(y_test, y_pred.argmax(-1), display_labels=dataset2.classes)\nplt.xticks(rotation=90)\nplt.plot()","metadata":{"execution":{"iopub.status.busy":"2024-11-04T21:40:06.197633Z","iopub.execute_input":"2024-11-04T21:40:06.198482Z","iopub.status.idle":"2024-11-04T21:41:28.324022Z","shell.execute_reply.started":"2024-11-04T21:40:06.198440Z","shell.execute_reply":"2024-11-04T21:41:28.323054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nprint(classification_report(y_test, y_pred.argmax(-1), target_names=dataset1.classes))","metadata":{"execution":{"iopub.status.busy":"2024-11-04T21:41:34.568686Z","iopub.execute_input":"2024-11-04T21:41:34.569100Z","iopub.status.idle":"2024-11-04T21:41:34.584715Z","shell.execute_reply.started":"2024-11-04T21:41:34.569059Z","shell.execute_reply":"2024-11-04T21:41:34.583660Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfor i in range(10):  # Show 3 images\n    img, label = train_data[i]\n\n    # Get the image data (tensor) and convert it back to a NumPy array for manipulation\n    img = img.numpy()\n\n    # Convert the color channels from (channels, height, width) to (height, width, channels) for pyplot\n    img = img.transpose((1, 2, 0))\n\n    # Get the label name from the dataset class labels\n    label_name = dataset2.classes[label]\n\n    # Plot the image with a title (including label name)\n    plt.imshow(img)\n    plt.title(f\"Image: {i+1}, Label: {label_name}\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-11-04T21:41:39.620707Z","iopub.execute_input":"2024-11-04T21:41:39.621504Z","iopub.status.idle":"2024-11-04T21:41:42.323204Z","shell.execute_reply.started":"2024-11-04T21:41:39.621455Z","shell.execute_reply":"2024-11-04T21:41:42.322062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision.utils import make_grid\n\nloader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=32)\n\n  \nbatch, labels = next(iter(loader))\n\ngrid = make_grid(batch).permute(1, 2, 0) # результатом є тензор\n\nplt.imshow(grid)","metadata":{"execution":{"iopub.status.busy":"2024-11-04T21:41:46.707436Z","iopub.execute_input":"2024-11-04T21:41:46.708137Z","iopub.status.idle":"2024-11-04T21:41:47.497952Z","shell.execute_reply.started":"2024-11-04T21:41:46.708097Z","shell.execute_reply":"2024-11-04T21:41:47.497021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}