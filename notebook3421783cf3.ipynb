{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9846350,"sourceType":"datasetVersion","datasetId":6041268}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nimport torch.nn as nn\nfrom torchvision import datasets, transforms\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T22:24:30.437687Z","iopub.execute_input":"2024-11-25T22:24:30.437967Z","iopub.status.idle":"2024-11-25T22:24:33.524669Z","shell.execute_reply.started":"2024-11-25T22:24:30.437934Z","shell.execute_reply":"2024-11-25T22:24:33.523933Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# images_path = '/kaggle/input/itstep-exam-2/ship_images'\nimages_path = '/kaggle/input/airbus-ship-detection/train_v2'\ncsv_path = '/kaggle/input/airbus-ship-detection/train_ship_segmentations_v2.csv'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T20:19:42.965140Z","iopub.execute_input":"2024-12-04T20:19:42.965428Z","iopub.status.idle":"2024-12-04T20:19:42.988820Z","shell.execute_reply.started":"2024-12-04T20:19:42.965397Z","shell.execute_reply":"2024-12-04T20:19:42.988055Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"df = pd.read_csv(csv_path)\nprint(\"Розмір датафрейму:\", df.shape)\nprint(df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T22:24:33.531007Z","iopub.execute_input":"2024-11-25T22:24:33.531227Z","iopub.status.idle":"2024-11-25T22:24:34.140223Z","shell.execute_reply.started":"2024-11-25T22:24:33.531204Z","shell.execute_reply":"2024-11-25T22:24:34.138980Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Завантаження CSV з даними\ndf = pd.read_csv('/kaggle/input/airbus-ship-detection/train_ship_segmentations_v2.csv')\n\n# Перевірка наявних колонок\n# print(df.head())\n\n# Очищення даних від рядків з NaN у стовпці EncodedPixels\ndf_cleaned = df.dropna(subset=['EncodedPixels'])\n\n# Підрахунок кількості кораблів на кожному зображенні\nship_counts = df_cleaned.groupby('ImageId').size()\n\n# Виведення кількості кораблів для кожного зображення\nprint(ship_counts)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T22:24:34.143525Z","iopub.execute_input":"2024-11-25T22:24:34.143939Z","iopub.status.idle":"2024-11-25T22:24:34.786100Z","shell.execute_reply.started":"2024-11-25T22:24:34.143911Z","shell.execute_reply":"2024-11-25T22:24:34.785217Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_cleaned","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T22:24:34.787416Z","iopub.execute_input":"2024-11-25T22:24:34.787817Z","iopub.status.idle":"2024-11-25T22:24:34.800797Z","shell.execute_reply.started":"2024-11-25T22:24:34.787776Z","shell.execute_reply":"2024-11-25T22:24:34.799917Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['ships_count'] = df.groupby('ImageId')['EncodedPixels'].transform('count')\n\n# Візуалізація розподілу кількості кораблів\nship_counts = df.groupby('ImageId')['ships_count'].max()\nplt.figure(figsize=(10, 6))\nship_counts.hist(bins=10)\nplt.title('Розподіл кількості кораблів на зображення (до очищення)')\nplt.xlabel('Кількість кораблів')\nplt.ylabel('Кількість зображень')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T22:24:34.801931Z","iopub.execute_input":"2024-11-25T22:24:34.802185Z","iopub.status.idle":"2024-11-25T22:24:35.309106Z","shell.execute_reply.started":"2024-11-25T22:24:34.802160Z","shell.execute_reply":"2024-11-25T22:24:35.308260Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Очищення даних від рядків з NaN у стовпці EncodedPixels\ndf_cleaned = df.dropna(subset=['EncodedPixels']).reset_index(drop=True)\n\n# Кількість унікальних зображень з кораблями\nunique_images_with_ships = df_cleaned['ImageId'].nunique()\n\n# Підрахунок кількості кораблів на кожному зображенні (групуємо за ImageId)\nship_counts = df_cleaned.groupby('ImageId').size()\n\n# Виведення кількості унікальних зображень з кораблями\nprint(\"Кількість зображень з кораблями:\", unique_images_with_ships)\n\n# Візуалізація розподілу кількості кораблів на кожному зображенні\nplt.figure(figsize=(10, 6))\nship_counts.hist(bins=10)\nplt.title('Розподіл кількості кораблів на зображення (після очищення даних)')\nplt.xlabel('Кількість кораблів')\nplt.ylabel('Кількість зображень')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T22:24:35.310189Z","iopub.execute_input":"2024-11-25T22:24:35.310455Z","iopub.status.idle":"2024-11-25T22:24:35.569910Z","shell.execute_reply.started":"2024-11-25T22:24:35.310430Z","shell.execute_reply":"2024-11-25T22:24:35.569035Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install segmentation-models-pytorch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T22:24:35.570952Z","iopub.execute_input":"2024-11-25T22:24:35.571224Z","iopub.status.idle":"2024-11-25T22:24:43.944413Z","shell.execute_reply.started":"2024-11-25T22:24:35.571199Z","shell.execute_reply":"2024-11-25T22:24:43.943556Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport cv2\nfrom torch.utils.data import Dataset\nimport matplotlib.pyplot as plt\nfrom torchvision import transforms\nfrom PIL import Image\nfrom segmentation_models_pytorch.encoders import get_preprocessing_fn\n\nclass ShipDataset(Dataset):\n    def __init__(self, images_path, df_cleaned, height=768, width=768, image_ids=None):\n        self.images_path = images_path\n        self.df_cleaned = df_cleaned\n        self.height = height\n        self.width = width\n        self.image_ids = image_ids if image_ids is not None else df_cleaned['ImageId'].unique()\n        \n    def __len__(self):\n        return len(self.image_ids)\n    \n    def rle_to_mask(self, rle, height, width):\n        \"\"\"\n        Перетворює Run-Length Encoding в маску розміру height x width.\n        :param rle: рядок, що містить Run-Length Encoding (пари start, length)\n        :param height: висота маски\n        :param width: ширина маски\n        :return: маска у вигляді numpy масиву\n        \"\"\"\n        mask = np.zeros(height * width, dtype=np.uint8)  # маска початково пуста\n        rle_values = list(map(int, rle.split()))  # розділяємо рядок на числа\n        \n        for i in range(0, len(rle_values), 2):\n            start = rle_values[i] - 1  # початковий піксель\n            length = rle_values[i+1]  # довжина відрізка\n            \n            # Переводимо лінійний індекс в двовимірні координати (рядок, стовпець)\n            start_row = start // width  # визначаємо рядок\n            start_col = start % width   # визначаємо стовпець\n            \n            # Заповнюємо маску відповідними пікселями\n            for j in range(length):\n                row = (start + j) // width  # обчислюємо новий рядок\n                col = (start + j) % width   # обчислюємо новий стовпець\n                \n                # Перевірка, чи не виходимо за межі маски\n                if row < height and col < width:\n                    mask[row * width + col] = 1  # встановлюємо піксель в 1\n\n        return mask.reshape((height, width)).T  # Перетворюємо маску у формат 2D (height, width)\n\n    def combine_masks(self, masks, height, width):\n        \"\"\"\n        Об'єднує маски для кількох кораблів в одну\n        \"\"\"\n        if masks:\n            combined_mask = np.zeros((height, width), dtype=np.uint8)\n            for mask in masks:\n                combined_mask = np.maximum(combined_mask, mask)  # Об'єднуємо маски\n        else:\n            combined_mask = np.zeros((height, width), dtype=np.uint8)\n        return combined_mask\n    \n    def split_image(self, image, mask, part_size=256):\n        \"\"\"\n        Розрізає зображення та маску на 9 частин 256x256\n        Вибирає ту частину, де найбільше пікселів кораблів\n        \"\"\"\n        best_part_idx = None\n        max_ship_pixels = 0\n\n        # Розрізаємо зображення на 9 частин (3x3)\n        image_parts = []\n        mask_parts = []\n        \n        for i in range(3):  # 3 рядки\n            for j in range(3):  # 3 стовпці\n                start_row = i * part_size\n                start_col = j * part_size\n                end_row = start_row + part_size\n                end_col = start_col + part_size\n\n                image_part = image[start_row:end_row, start_col:end_col]\n                mask_part = mask[start_row:end_row, start_col:end_col]\n\n                image_parts.append(image_part)\n                mask_parts.append(mask_part)\n\n                # Підраховуємо кількість пікселів кораблів (1 в масці)\n                ship_pixels = np.sum(mask_part)\n                if ship_pixels > max_ship_pixels:\n                    max_ship_pixels = ship_pixels\n                    best_part_idx = len(image_parts) - 1  # Зберігаємо індекс найкращої частини\n\n        # Повертаємо найкращу частину зображення та маски\n        return image_parts[best_part_idx], mask_parts[best_part_idx]\n    \n    def __getitem__(self, idx):\n        # Отримуємо ImageId\n        image_id = self.image_ids[idx]\n        \n        # Завантажуємо зображення\n        image_path = f\"{self.images_path}/{image_id}\"\n        image = Image.open(image_path).convert('RGB')\n        image = np.array(image.resize((self.width, self.height)))  # Змінюємо розмір зображення\n\n        # Завантажуємо маски для поточного зображення\n        masks = []\n        encoded_pixels = self.df_cleaned[self.df_cleaned['ImageId'] == image_id]['EncodedPixels']\n        \n        for rle in encoded_pixels:\n            mask = self.rle_to_mask(rle, self.height, self.width)\n            masks.append(mask)\n        \n        # Об'єднуємо маски для всіх кораблів\n        combined_mask = self.combine_masks(masks, self.height, self.width)\n        \n        # Ріжемо зображення та маску на 9 частин і вибираємо найкращу частину\n        best_image_part, best_mask_part = self.split_image(image, combined_mask)\n\n        preprocess_input = get_preprocessing_fn('resnet34', pretrained='imagenet')\n    \n        # Застосовуємо preprocess_input до зображення\n        best_image_part = preprocess_input(best_image_part)\n        \n        # Перетворення зображення в тензор\n        transform = transforms.ToTensor()\n        best_image_part = transform(best_image_part)\n        \n        # Виводимо кількість масок для поточного зображення\n        # print(f\"Number of ships (masks) in {image_id}: {len(masks)}\")\n        \n        return best_image_part, best_mask_part\n\n# Завантажуємо дані\ndf = pd.read_csv('/kaggle/input/airbus-ship-detection/train_ship_segmentations_v2.csv')\n\n# Очищення даних від рядків з NaN у стовпці EncodedPixels\ndf_cleaned = df.dropna(subset=['EncodedPixels'])\n\n# Створюємо датасет\nimages_path = '/kaggle/input/airbus-ship-detection/train_v2'\ndataset = ShipDataset(images_path=images_path, df_cleaned=df_cleaned)\n\n# Виводимо зображення і маску для перевірки\nimage, mask = dataset[2]  # Отримуємо перший елемент датасету\n\n# Виводимо зображення\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nplt.imshow(image.permute(1, 2, 0))  # перетворюємо з (C, H, W) в (H, W, C)\nplt.title('Best Image Part')\n\n# Виводимо маску\nplt.subplot(1, 2, 2)\nplt.imshow(mask, cmap='gray')\nplt.title('Best Mask Part')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T22:24:43.946508Z","iopub.execute_input":"2024-11-25T22:24:43.946949Z","iopub.status.idle":"2024-11-25T22:24:47.233987Z","shell.execute_reply.started":"2024-11-25T22:24:43.946903Z","shell.execute_reply":"2024-11-25T22:24:47.233163Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Розділення ImageId на тренувальну та тестову вибірки\n# train_ids, test_ids = train_test_split(dataset.image_ids, test_size=0.2, random_state=42)\nmain_ids, small_ids = train_test_split(dataset.image_ids, test_size=0.1, random_state=42)\n\n# Крок 2: Розділяємо 10% частину на тренувальну і тестову\ntrain_ids, test_ids = train_test_split(small_ids, test_size=0.2, random_state=42)\n\n# Створення DataFrame для тренувальних і тестових даних\ntrain_df = df_cleaned[df_cleaned['ImageId'].isin(train_ids)]\ntest_df = df_cleaned[df_cleaned['ImageId'].isin(test_ids)]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T22:24:47.235350Z","iopub.execute_input":"2024-11-25T22:24:47.236072Z","iopub.status.idle":"2024-11-25T22:24:47.258286Z","shell.execute_reply.started":"2024-11-25T22:24:47.236031Z","shell.execute_reply":"2024-11-25T22:24:47.257380Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Train size: {train_df.shape[0]}\")  # Кількість рядків у тренувальному наборі\nprint(f\"Test size: {test_df.shape[0]}\") ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T22:24:47.259436Z","iopub.execute_input":"2024-11-25T22:24:47.259779Z","iopub.status.idle":"2024-11-25T22:24:47.270545Z","shell.execute_reply.started":"2024-11-25T22:24:47.259751Z","shell.execute_reply":"2024-11-25T22:24:47.269780Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\n# Тренувальний датасет\ntrain_dataset = ShipDataset(image_ids=train_ids, df_cleaned=train_df, images_path=images_path)\n\n# Тестовий датасет\ntest_dataset = ShipDataset(image_ids=test_ids, df_cleaned=test_df, images_path=images_path)\n\n# DataLoader\ntrain_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T22:24:47.271682Z","iopub.execute_input":"2024-11-25T22:24:47.271962Z","iopub.status.idle":"2024-11-25T22:24:47.282770Z","shell.execute_reply.started":"2024-11-25T22:24:47.271937Z","shell.execute_reply":"2024-11-25T22:24:47.281976Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(train_loader), len(test_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T22:24:47.285611Z","iopub.execute_input":"2024-11-25T22:24:47.285871Z","iopub.status.idle":"2024-11-25T22:24:47.299942Z","shell.execute_reply.started":"2024-11-25T22:24:47.285847Z","shell.execute_reply":"2024-11-25T22:24:47.299127Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import segmentation_models_pytorch as smp\nimport torch\n\n# Створення моделі UNet\nmodel = smp.Unet(\n    encoder_name=\"resnet34\",  # Основна архітектура\n    encoder_weights=\"imagenet\",  # Попередньо натреновані ваги\n    in_channels=3,  # Кількість каналів на вході (RGB)\n    classes=1,  # Кількість класів (1 для бінарної сегментації)\n)\n\nmodel\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T22:24:47.300882Z","iopub.execute_input":"2024-11-25T22:24:47.301100Z","iopub.status.idle":"2024-11-25T22:24:47.944005Z","shell.execute_reply.started":"2024-11-25T22:24:47.301079Z","shell.execute_reply":"2024-11-25T22:24:47.943070Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Заморожуємо енкодер (встановлюємо requires_grad = False для його параметрів)\nfor param in model.encoder.parameters():\n    param.requires_grad = False\n\n# Перевіряємо, чи енкодер дійсно заморожений\nfor name, param in model.named_parameters():\n    print(f\"{name}: requires_grad={param.requires_grad}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T22:24:47.945362Z","iopub.execute_input":"2024-11-25T22:24:47.945766Z","iopub.status.idle":"2024-11-25T22:24:47.953113Z","shell.execute_reply.started":"2024-11-25T22:24:47.945727Z","shell.execute_reply":"2024-11-25T22:24:47.952158Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -q torchsummary","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T22:24:47.954330Z","iopub.execute_input":"2024-11-25T22:24:47.955087Z","iopub.status.idle":"2024-11-25T22:24:56.159477Z","shell.execute_reply.started":"2024-11-25T22:24:47.955048Z","shell.execute_reply":"2024-11-25T22:24:56.158351Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchsummary import summary\n\n# Перенесення моделі на пристрій (CPU або GPU)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\n# Виведення summary моделі\nsummary(model, input_size=(3, 256, 256))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T22:24:56.161125Z","iopub.execute_input":"2024-11-25T22:24:56.161571Z","iopub.status.idle":"2024-11-25T22:24:56.539524Z","shell.execute_reply.started":"2024-11-25T22:24:56.161525Z","shell.execute_reply":"2024-11-25T22:24:56.538623Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import torch\n# import torch.nn.functional as F\n# import segmentation_models_pytorch as smp\n\n# class DiceBCELoss(torch.nn.Module):\n#     def __init__(self, dice_weight=0.5, bce_weight=0.5):\n#         super(DiceBCELoss, self).__init__()\n#         self.dice_weight = dice_weight\n#         self.bce_weight = bce_weight\n\n#         # Ініціалізуємо DiceLoss від segmentation_models_pytorch\n#         self.dice_loss = smp.losses.DiceLoss(mode=\"binary\")\n        \n#     def forward(self, pred, target):\n#         # BCELoss (бінарна крос-ентропія)\n#         target = target.unsqueeze(1)\n#         bce_loss = F.binary_cross_entropy_with_logits(pred, target)\n        \n#         # Dice Loss\n#         dice_loss = self.dice_loss(pred, target)\n        \n#         # Зважена сума обох втрат\n#         total_loss = self.bce_weight * bce_loss + self.dice_weight * dice_loss\n#         return total_loss\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T22:24:56.540844Z","iopub.execute_input":"2024-11-25T22:24:56.541219Z","iopub.status.idle":"2024-11-25T22:24:56.546474Z","shell.execute_reply.started":"2024-11-25T22:24:56.541179Z","shell.execute_reply":"2024-11-25T22:24:56.545483Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install kornia","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T22:24:56.547886Z","iopub.execute_input":"2024-11-25T22:24:56.548275Z","iopub.status.idle":"2024-11-25T22:25:04.803111Z","shell.execute_reply.started":"2024-11-25T22:24:56.548238Z","shell.execute_reply":"2024-11-25T22:25:04.802050Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from kornia.losses import FocalLoss\n# import torch\n# import torch.nn.functional as F\n# import segmentation_models_pytorch as smp\n\n# class DiceFocalLoss(nn.Module):\n#     def __init__(self, dice_weight=0.5, focal_weight=0.5, gamma=2.0, alpha=0.25):\n#         super(DiceFocalLoss, self).__init__()\n#         self.dice_weight = dice_weight\n#         self.focal_weight = focal_weight\n#         self.dice_loss = smp.losses.DiceLoss(mode=\"binary\")\n#         self.focal_loss = FocalLoss(alpha=alpha, gamma=gamma, reduction=\"mean\")\n\n#     def forward(self, outputs, targets):\n#         # Переконуємось, що мітки у правильному форматі для кожної втрати\n#         dice_targets = targets.float()  # Для DiceLoss: float\n#         focal_targets = targets.long()  # Для FocalLoss: int64\n\n#         dice = self.dice_loss(outputs, dice_targets)\n#         focal = self.focal_loss(outputs, focal_targets)\n#         return self.dice_weight * dice + self.focal_weight * focal\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T22:25:04.804631Z","iopub.execute_input":"2024-11-25T22:25:04.804937Z","iopub.status.idle":"2024-11-25T22:25:04.809625Z","shell.execute_reply.started":"2024-11-25T22:25:04.804907Z","shell.execute_reply":"2024-11-25T22:25:04.808744Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from kornia.losses import FocalLoss\nimport torch\nimport torch.nn.functional as F\nimport segmentation_models_pytorch as smp\n\n# class CombinedLoss(nn.Module):\n#     def __init__(self, alpha=0.5, beta=0.5, focal_alpha=0.25, focal_gamma=2.0, reduction='mean'):\n#         super().__init__()\n#         self.alpha = alpha  # Вага для Dice Loss\n#         self.beta = beta    # Вага для Focal Loss\n#         self.dice_loss = smp.losses.DiceLoss(mode=\"binary\")\n#         self.focal_loss = FocalLoss(alpha=focal_alpha, gamma=focal_gamma, reduction=reduction)\n\n#     def forward(self, pred, target):\n#         # Якщо бінарна класифікація, видаляємо зайвий канал\n#         if pred.shape[1] == 1:\n#             pred = pred.squeeze(1)\n\n#         dice = self.dice_loss(pred, target)\n#         focal = self.focal_loss(pred, target)\n#         return self.alpha * dice + self.beta * focal\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T22:25:04.810895Z","iopub.execute_input":"2024-11-25T22:25:04.811744Z","iopub.status.idle":"2024-11-25T22:25:05.083997Z","shell.execute_reply.started":"2024-11-25T22:25:04.811696Z","shell.execute_reply":"2024-11-25T22:25:05.083138Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# class CombinedLoss(nn.Module):\n#     def __init__(self, alpha=0.5, beta=0.5, focal_alpha=0.25, focal_gamma=2.0, reduction='mean'):\n#         super().__init__()\n#         self.alpha = alpha  # Вага для Dice Loss\n#         self.beta = beta    # Вага для Focal Loss\n#         self.dice_loss = smp.losses.DiceLoss(mode=\"binary\")\n#         self.focal_loss = FocalLoss(alpha=focal_alpha, gamma=focal_gamma, reduction=reduction)\n\n#     def forward(self, pred, target):\n#         # Якщо бінарна класифікація, видаляємо зайвий канал\n#         if pred.shape[1] == 1:\n#             pred = pred.squeeze(1)\n\n#         # Переконуємося, що розміри таргету відповідають передбаченням\n#         if target.shape[2:] != pred.shape[2:]:\n#             target = torch.nn.functional.interpolate(target.unsqueeze(1), size=pred.shape[2:], mode='nearest').squeeze(1)\n\n#         # Переконуємося, що тип даних таргету правильний\n#         target = target.float()  # DiceLoss і FocalLoss очікують float\n\n#         # Перевіряємо, чи правильні розміри\n        # assert pred.shape == target.shape, f\"Pred shape {pred.shape} does not match target shape {target.shape}\"\n\n        # # Обчислення Dice та Focal лоссів\n        # dice = self.dice_loss(pred, target)\n        # focal = self.focal_loss(pred, target)\n\n        # # Комбінований лосс\n        # return self.alpha * dice + self.beta * focal\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T22:25:05.085384Z","iopub.execute_input":"2024-11-25T22:25:05.086197Z","iopub.status.idle":"2024-11-25T22:25:05.090623Z","shell.execute_reply.started":"2024-11-25T22:25:05.086168Z","shell.execute_reply":"2024-11-25T22:25:05.089639Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# loss_fn = DiceFocalLoss(dice_weight=0.5, focal_weight=0.5, gamma=2.0, alpha=0.25)\n\n#loss_fn = CombinedLoss(alpha=0.5, beta=0.5, focal_alpha=0.25, focal_gamma=2.0)\nloss_fn = smp.losses.DiceLoss(mode=\"binary\")\n\n# loss_fn = DiceBCELoss(dice_weight=0.5, bce_weight=0.5)\n\n# ініціалізація оптимізатора\n# optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T22:25:05.091678Z","iopub.execute_input":"2024-11-25T22:25:05.091987Z","iopub.status.idle":"2024-11-25T22:25:05.105810Z","shell.execute_reply.started":"2024-11-25T22:25:05.091961Z","shell.execute_reply":"2024-11-25T22:25:05.105038Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.0005)\n\n# Підрахунок кількості параметрів\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\nnon_trainable_params = sum(p.numel() for p in model.parameters() if not p.requires_grad)\n\nprint(f\"Trainable parameters: {trainable_params}\")\nprint(f\"Non-trainable parameters: {non_trainable_params}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T22:25:05.106921Z","iopub.execute_input":"2024-11-25T22:25:05.107616Z","iopub.status.idle":"2024-11-25T22:25:05.118526Z","shell.execute_reply.started":"2024-11-25T22:25:05.107555Z","shell.execute_reply":"2024-11-25T22:25:05.117790Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Втрата та оптимізатор\n# loss_fn = smp.losses.DiceLoss(mode=\"binary\")\n# optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T22:25:05.119516Z","iopub.execute_input":"2024-11-25T22:25:05.119875Z","iopub.status.idle":"2024-11-25T22:25:05.131790Z","shell.execute_reply.started":"2024-11-25T22:25:05.119835Z","shell.execute_reply":"2024-11-25T22:25:05.130933Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import gc\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\nnum_epochs = 15\ntrain_loss_history = []\nval_loss_history = []\n\nfor epoch in range(num_epochs):\n    model.train()\n    train_loss = 0.0\n    \n    # Тренувальний крок\n    for images, masks in train_loader:\n        # Переносимо на пристрій\n        # images = images.to(device)\n        # masks = masks.to(device)\n        images = images.to(device).float()\n        masks = masks.to(device).float()\n\n        # Обчислення forward проходу\n        optimizer.zero_grad()\n        outputs = model(images)\n        # outputs = outputs.squeeze(1)\n        loss = loss_fn(outputs, masks)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n\n    train_loss_avg = train_loss / len(train_loader)\n    train_loss_history.append(train_loss_avg)\n\n    torch.cuda.empty_cache()\n    gc.collect()\n\n    # Оцінка на валідаційних даних\n    model.eval()\n    val_loss = 0.0\n    with torch.no_grad():\n        for images, masks in test_loader:\n            # images = images.to(device)\n            # masks = masks.to(device)\n            images = images.to(device).float()\n            masks = masks.to(device).float()\n\n            outputs = model(images)\n            # outputs = outputs.squeeze(1)\n            loss = loss_fn(outputs, masks)\n            val_loss += loss.item()\n\n    val_loss_avg = val_loss / len(test_loader)\n    val_loss_history.append(val_loss_avg)\n\n    torch.cuda.empty_cache()\n    gc.collect()\n\n    # Виведення результатів кожного етапу\n    print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n          f\"Train Loss: {train_loss_avg:.4f}, \"\n          f\"Validation Loss: {val_loss_avg:.4f}\")\n\n# # Зберігаємо модель після тренування\n# torch.save(model.state_dict(), 'unet_model.pth')\n\n# # Виведення часу тренування\n# print(f\"Training completed in: {time.time() - start_time:.2f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T22:25:05.132738Z","iopub.execute_input":"2024-11-25T22:25:05.132985Z","iopub.status.idle":"2024-11-25T22:43:18.489631Z","shell.execute_reply.started":"2024-11-25T22:25:05.132961Z","shell.execute_reply":"2024-11-25T22:43:18.488645Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nnum_epochs = 15\nplt.plot(range(1, num_epochs+1), train_loss_history, label=\"Train Loss\")\nplt.plot(range(1, num_epochs+1), val_loss_history, label=\"Validation Loss\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Loss Curve')\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T22:43:18.490867Z","iopub.execute_input":"2024-11-25T22:43:18.491156Z","iopub.status.idle":"2024-11-25T22:43:18.759256Z","shell.execute_reply.started":"2024-11-25T22:43:18.491130Z","shell.execute_reply":"2024-11-25T22:43:18.758347Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def denormalize_image(image):\n    \"\"\"\n    Денормалізує зображення після `preprocess_input` на GPU або CPU.\n    \"\"\"\n    mean = [0.485, 0.456, 0.406]  # Середні значення для ImageNet\n    std = [0.229, 0.224, 0.225]   # Стандартні відхилення для ImageNet\n\n    # Переносимо mean і std на той самий пристрій, де знаходяться зображення\n    mean = torch.tensor(mean).reshape(1, 3, 1, 1).to(image.device)\n    std = torch.tensor(std).reshape(1, 3, 1, 1).to(image.device)\n\n    # Денормалізація\n    image = image * std + mean  # Зворотне масштабування\n    return image\n\n\ndef visualize_results(model, test_loader, device, num_images=15):\n    \"\"\"\n    Візуалізує результати моделі на тестовому датасеті, використовуючи денормалізацію для зображень.\n    \"\"\"\n    model.eval()  # Переводимо модель в режим оцінки\n    test_iter = iter(test_loader)  # Ітератор для тестових даних\n    \n    images_shown = 0  # Лічильник показаних зображень\n    \n    with torch.no_grad():  # Виключаємо градієнти\n        while images_shown < num_images:\n            images, true_masks = next(test_iter)\n            images = images.to(device).float()  # Приводимо до float і переносимо на GPU\n            true_masks = true_masks.to(device).float()  # Приводимо до float і переносимо на GPU\n            \n            # Передбачення масок\n            pred_masks = model(images)  # Виклик моделі\n            pred_masks = torch.sigmoid(pred_masks)  # Застосовуємо sigmoid для переводу в [0, 1]\n            pred_masks = (pred_masks > 0.5).float()  # Бінаризуємо\n            \n            # Денормалізація зображень для візуалізації\n            images_denormalized = denormalize_image(images)\n            \n            # Візуалізація\n            for j in range(len(images)):\n                if images_shown >= num_images:  # Перевірка на кількість виведених зображень\n                    break\n                \n                fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n                \n                # Оригінальне зображення (денормалізоване)\n                ax[0].imshow(images_denormalized[j].cpu().permute(1, 2, 0).clip(0, 1))  # Переносимо з GPU на CPU\n                ax[0].set_title(\"Original Image (Denormalized)\")\n                ax[0].axis(\"off\")\n                \n                # Реальна маска\n                ax[1].imshow(true_masks[j].cpu().squeeze(), cmap=\"gray\")  # Переносимо з GPU на CPU\n                ax[1].set_title(\"True Mask\")\n                ax[1].axis(\"off\")\n                \n                # Передбачена маска\n                ax[2].imshow(pred_masks[j].cpu().squeeze(), cmap=\"gray\")  # Переносимо з GPU на CPU\n                ax[2].set_title(\"Predicted Mask\")\n                ax[2].axis(\"off\")\n                \n                images_shown += 1  # Збільшуємо лічильник\n                plt.show()\n\n# Визначте пристрій\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Перенесіть модель на пристрій\nmodel.to(device)\n\n# Виклик функції\nvisualize_results(model, test_loader, device, num_images=15)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T22:43:18.760239Z","iopub.execute_input":"2024-11-25T22:43:18.760507Z","iopub.status.idle":"2024-11-25T22:43:25.844581Z","shell.execute_reply.started":"2024-11-25T22:43:18.760481Z","shell.execute_reply":"2024-11-25T22:43:25.843778Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def visualize_results(model, test_loader, device, num_images=1):\n#     \"\"\"\n#     Візуалізує результати моделі на тестовому датасеті, використовуючи денормалізацію для зображень.\n#     \"\"\"\n#     model.eval()  # Переводимо модель в режим оцінки\n#     test_iter = iter(test_loader)  # Ітератор для тестових даних\n\n#     with torch.no_grad():  # Виключаємо градієнти\n#         for i in range(num_images):\n#             images, true_masks = next(test_iter)\n#             images = images.to(device).float()  # Приводимо до float і переносимо на GPU\n#             true_masks = true_masks.to(device).float()  # Приводимо до float і переносимо на GPU\n            \n#             # Передбачення масок\n#             pred_masks = model(images)  # Виклик моделі\n#             pred_masks = torch.sigmoid(pred_masks)  # Застосовуємо sigmoid для переводу в [0, 1]\n#             pred_masks = (pred_masks > 0.5).float()  # Бінаризуємо\n            \n#             # Денормалізація зображень для візуалізації\n#             images_denormalized = denormalize_image(images)\n\n#             # Візуалізація\n#             for j in range(len(images)):\n#                 fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n                \n#                 # Оригінальне зображення (денормалізоване)\n#                 ax[0].imshow(images_denormalized[j].cpu().permute(1, 2, 0).clip(0, 1))  # Переносимо з GPU на CPU\n#                 ax[0].set_title(\"Original Image (Denormalized)\")\n#                 ax[0].axis(\"off\")\n                \n#                 # Реальна маска\n#                 ax[1].imshow(true_masks[j].cpu().squeeze(), cmap=\"gray\")  # Переносимо з GPU на CPU\n#                 ax[1].set_title(\"True Mask\")\n#                 ax[1].axis(\"off\")\n                \n#                 # Передбачена маска\n#                 ax[2].imshow(pred_masks[j].cpu().squeeze(), cmap=\"gray\")  # Переносимо з GPU на CPU\n#                 ax[2].set_title(\"Predicted Mask\")\n#                 ax[2].axis(\"off\")\n                \n#                 plt.show()\n\n# # Визначте пристрій\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# # Перенесіть модель на пристрій\n# model.to(device)\n\n# # Виклик функції\n# visualize_results(model, test_loader, device, num_images=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}